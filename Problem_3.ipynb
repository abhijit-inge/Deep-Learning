{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 3: Training and Fine-tuning on Fashion MNIST and MNIST\n",
    "Training neural networks with a huge number of parameters on a small dataset greatly affects the networks' generalization ability, often resulting in overfitting. Therefore, more often in practice, one would fine-tune existing networks that are trained on a larger dataset by continuing training on a smaller dataset. To get familiar with the fine-tuning procedure, in this problem you need to train a model from scratch on Fashion MNIST dataset and then fine-tune it on MNIST dataset. Note that we are training models on these two toy datasets because of limited computational resources. In most cases, we train models on ImageNet and fine-tune them on smaller datasets.\n",
    "\n",
    "* <b>Learning Objective:</b> In Problem 2, you implemented a covolutional neural network to perform classification task in TensorFlow. In this part of the assignment, we will show you how to use TensorFlow to fine-tune a trained network on a different task.\n",
    "* <b>Provided Codes:</b> We provide the the dataset downloading and preprocessing codes, conv2d(), and fc() functions to build the model performing the fine-tuning task.\n",
    "* <b>TODOs:</b> Train a model from scratch on Fashion MNIST dataset and then fine-tune it on MNIST dataset. Both the training loss and the training accuracy need to be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def download_data(download_root='data/', dataset='mnist'):\n",
    "    if dataset == 'mnist':\n",
    "        data_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    elif dataset == 'fashion_mnist':\n",
    "        data_url = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'\n",
    "    else:\n",
    "        raise ValueError('Please specify mnist or fashion_mnist.')\n",
    "\n",
    "    data_dir = osp.join(download_root, dataset)\n",
    "    if osp.exists(data_dir):\n",
    "        print('The dataset was downloaded.')\n",
    "        return\n",
    "    else:\n",
    "        os.mkdir(data_dir)\n",
    "\n",
    "    keys = ['train-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz',\n",
    "            'train-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    for k in keys:\n",
    "        url = (data_url+k).format(**locals())\n",
    "        target_path = osp.join(data_dir, k)\n",
    "        cmd = ['curl', url, '-o', target_path]\n",
    "        print('Downloading ', k)\n",
    "        subprocess.call(cmd)\n",
    "        cmd = ['gzip', '-d', target_path]\n",
    "        print('Unzip ', k)\n",
    "        subprocess.call(cmd)\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    num_train = 60000\n",
    "    num_test = 10000\n",
    "\n",
    "    def load_file(filename, num, shape):\n",
    "        fd = open(osp.join(data_dir, filename))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        return loaded[num:].reshape(shape).astype(np.float)\n",
    "\n",
    "    train_image = load_file('train-images-idx3-ubyte', 16, (num_train, 28, 28, 1))\n",
    "    train_label = load_file('train-labels-idx1-ubyte', 8, num_train)\n",
    "    test_image = load_file('t10k-images-idx3-ubyte', 16, (num_test, 28, 28, 1))\n",
    "    test_label = load_file('t10k-labels-idx1-ubyte', 8, num_test)\n",
    "    return train_image, train_label, test_image, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset was downloaded.\n",
      "The dataset was downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Download MNIST and Fashion MNIST\n",
    "download_data(dataset='mnist')\n",
    "download_data(dataset='fashion_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def conv2d(input, output_shape, k=4, s=2, name='conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        return slim.conv2d(input, output_shape, [k, k], stride=s)\n",
    "\n",
    "\n",
    "def fc(input, output_shape, act_fn=tf.nn.relu, name='fc'):\n",
    "    with tf.variable_scope(name):\n",
    "        return slim.fully_connected(input, output_shape, activation_fn=act_fn)\n",
    "\n",
    "\n",
    "def train(batch_size=100, num_epoch=5, learning_rate=1e-5,\n",
    "          num_train=60000, num_test=10000):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # Build the model\n",
    "    X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "    Y = tf.placeholder(tf.int64, [None])\n",
    "    labels = tf.one_hot(Y, 10)\n",
    "    _ = conv2d(X, 32, name='conv1')\n",
    "    _ = conv2d(_, 64, name='conv2')\n",
    "    _ = conv2d(_, 256, name='conv3')\n",
    "    _ = tf.reshape(_, [-1, np.prod(_.get_shape().as_list()[1:])])\n",
    "    _ = fc(_, 256, name='fc1')\n",
    "    logits = fc(_, 10, act_fn=None, name='fc2')\n",
    "\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    loss_op = tf.reduce_mean(loss)\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    predict = tf.argmax(logits, 1)\n",
    "    correct = tf.equal(predict, Y)\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_loss = []\n",
    "    total_accuracy = []\n",
    "    log_step = 50\n",
    "\n",
    "\n",
    "    print('\\033[93mTrain Fashion MNIST\\033[0m')\n",
    "    X_train, Y_train, X_test, Y_test = load_data('data/fashion_mnist')\n",
    "    #############################################################################\n",
    "    # TODO: Train the model on Fashion MNIST from scratch                       #\n",
    "    # and then fine-tune it on MNIST                                            #\n",
    "    # Collect the training loss and the training accuracy                       #\n",
    "    # fetched from each iteration                                               #\n",
    "    # After the two stages of the training, the length of                       #\n",
    "    # total_loss and total_accuracy shuold be                                   #\n",
    "    # 2 *num_epoch * num_train / batch_size = 2 * 5 * 60000 / 100 = 6000        #\n",
    "    ############################################################################\n",
    "    # Train the model on Fashion MNIST\n",
    "    step=0\n",
    "    for epoch in range(num_epoch):\n",
    "        for i in range(num_train // batch_size):\n",
    "                X_ = X_train[i * batch_size:(i + 1) * batch_size][:]\n",
    "                Y_ = Y_train[i * batch_size:(i + 1) * batch_size]\n",
    "                global_step=step\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict ={X: X_,\n",
    "                           Y: Y_,\n",
    "                        }                \n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "                fetches = [train_op, loss_op, accuracy_op]\n",
    "                \n",
    "                \n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                total_loss.append(loss)\n",
    "                total_accuracy.append(accuracy)\n",
    "\n",
    "                if step % log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "        print('[Epoch {}] loss: {}, accuracy: {}'.format(epoch, loss, accuracy))\n",
    "        #print \"total loss length after epoch %d is %d and length of total accuracy is %d\"%(epoch,len(total_loss),len(total_accuracy))\n",
    "\n",
    "\n",
    "    # Train the model on MNIST\n",
    "    print('\\033[93mTrain MNIST\\033[0m')\n",
    "    X_train, Y_train, X_test, Y_test = load_data('data/mnist')\n",
    "    for epoch in range(num_epoch):\n",
    "        for i in range(num_train // batch_size):\n",
    "                X_ = X_train[i * batch_size:(i + 1) * batch_size][:]\n",
    "                Y_ = Y_train[i * batch_size:(i + 1) * batch_size]\n",
    "                global_step=step\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict ={X: X_,\n",
    "                           Y: Y_,\n",
    "                        }                \n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "                fetches = [train_op, loss_op, accuracy_op]\n",
    "                \n",
    "                \n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                total_loss.append(loss)\n",
    "                total_accuracy.append(accuracy)\n",
    "\n",
    "                if step % log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "        print('[Epoch {}] loss: {}, accuracy: {}'.format(epoch, loss, accuracy))\n",
    "        #print \"total loss length after epoch %d is %d and length of total accuracy is %d\"%(epoch,len(total_loss),len(total_accuracy))\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return total_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mTrain Fashion MNIST\u001b[0m\n",
      "iteration (0): loss = 17.857, accuracy = 0.040\n",
      "iteration (50): loss = 0.706, accuracy = 0.840\n",
      "iteration (100): loss = 0.560, accuracy = 0.760\n",
      "iteration (150): loss = 0.577, accuracy = 0.770\n",
      "iteration (200): loss = 0.480, accuracy = 0.820\n",
      "iteration (250): loss = 0.291, accuracy = 0.920\n",
      "iteration (300): loss = 0.477, accuracy = 0.840\n",
      "iteration (350): loss = 0.366, accuracy = 0.890\n",
      "iteration (400): loss = 0.641, accuracy = 0.750\n",
      "iteration (450): loss = 0.425, accuracy = 0.850\n",
      "iteration (500): loss = 0.643, accuracy = 0.800\n",
      "iteration (550): loss = 0.490, accuracy = 0.850\n",
      "[Epoch 0] loss: 0.339965581894, accuracy: 0.899999976158\n",
      "iteration (600): loss = 0.197, accuracy = 0.960\n",
      "iteration (650): loss = 0.310, accuracy = 0.860\n",
      "iteration (700): loss = 0.311, accuracy = 0.910\n",
      "iteration (750): loss = 0.343, accuracy = 0.890\n",
      "iteration (800): loss = 0.336, accuracy = 0.890\n",
      "iteration (850): loss = 0.186, accuracy = 0.950\n",
      "iteration (900): loss = 0.368, accuracy = 0.890\n",
      "iteration (950): loss = 0.358, accuracy = 0.850\n",
      "iteration (1000): loss = 0.531, accuracy = 0.810\n",
      "iteration (1050): loss = 0.311, accuracy = 0.900\n",
      "iteration (1100): loss = 0.404, accuracy = 0.860\n",
      "iteration (1150): loss = 0.345, accuracy = 0.830\n",
      "[Epoch 1] loss: 0.266629487276, accuracy: 0.889999985695\n",
      "iteration (1200): loss = 0.173, accuracy = 0.950\n",
      "iteration (1250): loss = 0.263, accuracy = 0.910\n",
      "iteration (1300): loss = 0.265, accuracy = 0.920\n",
      "iteration (1350): loss = 0.236, accuracy = 0.900\n",
      "iteration (1400): loss = 0.272, accuracy = 0.880\n",
      "iteration (1450): loss = 0.160, accuracy = 0.930\n",
      "iteration (1500): loss = 0.288, accuracy = 0.890\n",
      "iteration (1550): loss = 0.307, accuracy = 0.860\n",
      "iteration (1600): loss = 0.477, accuracy = 0.830\n",
      "iteration (1650): loss = 0.262, accuracy = 0.920\n",
      "iteration (1700): loss = 0.317, accuracy = 0.900\n",
      "iteration (1750): loss = 0.252, accuracy = 0.890\n",
      "[Epoch 2] loss: 0.213449478149, accuracy: 0.910000026226\n",
      "iteration (1800): loss = 0.131, accuracy = 0.950\n",
      "iteration (1850): loss = 0.231, accuracy = 0.900\n",
      "iteration (1900): loss = 0.212, accuracy = 0.920\n",
      "iteration (1950): loss = 0.205, accuracy = 0.920\n",
      "iteration (2000): loss = 0.205, accuracy = 0.910\n",
      "iteration (2050): loss = 0.153, accuracy = 0.930\n",
      "iteration (2100): loss = 0.220, accuracy = 0.920\n",
      "iteration (2150): loss = 0.255, accuracy = 0.870\n",
      "iteration (2200): loss = 0.430, accuracy = 0.850\n",
      "iteration (2250): loss = 0.214, accuracy = 0.940\n",
      "iteration (2300): loss = 0.281, accuracy = 0.920\n",
      "iteration (2350): loss = 0.195, accuracy = 0.920\n",
      "[Epoch 3] loss: 0.180151924491, accuracy: 0.949999988079\n",
      "iteration (2400): loss = 0.117, accuracy = 0.950\n",
      "iteration (2450): loss = 0.210, accuracy = 0.920\n",
      "iteration (2500): loss = 0.172, accuracy = 0.960\n",
      "iteration (2550): loss = 0.179, accuracy = 0.910\n",
      "iteration (2600): loss = 0.168, accuracy = 0.930\n",
      "iteration (2650): loss = 0.119, accuracy = 0.950\n",
      "iteration (2700): loss = 0.196, accuracy = 0.940\n",
      "iteration (2750): loss = 0.212, accuracy = 0.890\n",
      "iteration (2800): loss = 0.377, accuracy = 0.860\n",
      "iteration (2850): loss = 0.162, accuracy = 0.960\n",
      "iteration (2900): loss = 0.262, accuracy = 0.920\n",
      "iteration (2950): loss = 0.177, accuracy = 0.930\n",
      "[Epoch 4] loss: 0.117278382182, accuracy: 0.97000002861\n",
      "\u001b[93mTrain MNIST\u001b[0m\n",
      "iteration (3000): loss = 8.159, accuracy = 0.110\n",
      "iteration (3050): loss = 0.204, accuracy = 0.930\n",
      "iteration (3100): loss = 0.173, accuracy = 0.970\n",
      "iteration (3150): loss = 0.110, accuracy = 0.950\n",
      "iteration (3200): loss = 0.270, accuracy = 0.930\n",
      "iteration (3250): loss = 0.079, accuracy = 0.970\n",
      "iteration (3300): loss = 0.211, accuracy = 0.930\n",
      "iteration (3350): loss = 0.087, accuracy = 0.960\n",
      "iteration (3400): loss = 0.049, accuracy = 0.990\n",
      "iteration (3450): loss = 0.082, accuracy = 0.960\n",
      "iteration (3500): loss = 0.054, accuracy = 0.980\n",
      "iteration (3550): loss = 0.059, accuracy = 0.980\n",
      "[Epoch 0] loss: 0.211229518056, accuracy: 0.980000019073\n",
      "iteration (3600): loss = 0.070, accuracy = 0.980\n",
      "iteration (3650): loss = 0.106, accuracy = 0.960\n",
      "iteration (3700): loss = 0.027, accuracy = 1.000\n",
      "iteration (3750): loss = 0.016, accuracy = 1.000\n",
      "iteration (3800): loss = 0.067, accuracy = 0.970\n",
      "iteration (3850): loss = 0.017, accuracy = 1.000\n",
      "iteration (3900): loss = 0.073, accuracy = 0.990\n",
      "iteration (3950): loss = 0.045, accuracy = 0.980\n",
      "iteration (4000): loss = 0.021, accuracy = 0.990\n",
      "iteration (4050): loss = 0.021, accuracy = 1.000\n",
      "iteration (4100): loss = 0.014, accuracy = 1.000\n",
      "iteration (4150): loss = 0.016, accuracy = 0.990\n",
      "[Epoch 1] loss: 0.163814634085, accuracy: 0.990000009537\n",
      "iteration (4200): loss = 0.030, accuracy = 0.990\n",
      "iteration (4250): loss = 0.057, accuracy = 0.970\n",
      "iteration (4300): loss = 0.030, accuracy = 0.990\n",
      "iteration (4350): loss = 0.009, accuracy = 1.000\n",
      "iteration (4400): loss = 0.024, accuracy = 1.000\n",
      "iteration (4450): loss = 0.010, accuracy = 1.000\n",
      "iteration (4500): loss = 0.035, accuracy = 0.990\n",
      "iteration (4550): loss = 0.012, accuracy = 1.000\n",
      "iteration (4600): loss = 0.013, accuracy = 1.000\n",
      "iteration (4650): loss = 0.008, accuracy = 1.000\n",
      "iteration (4700): loss = 0.007, accuracy = 1.000\n",
      "iteration (4750): loss = 0.004, accuracy = 1.000\n",
      "[Epoch 2] loss: 0.144032016397, accuracy: 0.990000009537\n",
      "iteration (4800): loss = 0.009, accuracy = 1.000\n",
      "iteration (4850): loss = 0.017, accuracy = 1.000\n",
      "iteration (4900): loss = 0.010, accuracy = 1.000\n",
      "iteration (4950): loss = 0.005, accuracy = 1.000\n",
      "iteration (5000): loss = 0.007, accuracy = 1.000\n",
      "iteration (5050): loss = 0.003, accuracy = 1.000\n",
      "iteration (5100): loss = 0.015, accuracy = 1.000\n",
      "iteration (5150): loss = 0.005, accuracy = 1.000\n",
      "iteration (5200): loss = 0.007, accuracy = 1.000\n",
      "iteration (5250): loss = 0.007, accuracy = 1.000\n",
      "iteration (5300): loss = 0.005, accuracy = 1.000\n",
      "iteration (5350): loss = 0.001, accuracy = 1.000\n",
      "[Epoch 3] loss: 0.115420855582, accuracy: 0.990000009537\n",
      "iteration (5400): loss = 0.006, accuracy = 1.000\n",
      "iteration (5450): loss = 0.006, accuracy = 1.000\n",
      "iteration (5500): loss = 0.004, accuracy = 1.000\n",
      "iteration (5550): loss = 0.002, accuracy = 1.000\n",
      "iteration (5600): loss = 0.004, accuracy = 1.000\n",
      "iteration (5650): loss = 0.001, accuracy = 1.000\n",
      "iteration (5700): loss = 0.005, accuracy = 1.000\n",
      "iteration (5750): loss = 0.009, accuracy = 0.990\n",
      "iteration (5800): loss = 0.010, accuracy = 1.000\n",
      "iteration (5850): loss = 0.002, accuracy = 1.000\n",
      "iteration (5900): loss = 0.002, accuracy = 1.000\n",
      "iteration (5950): loss = 0.006, accuracy = 1.000\n",
      "[Epoch 4] loss: 0.0732306241989, accuracy: 0.990000009537\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ8LMzHI5JMzMLJdDwszMcv0PrwtQVD5+d0kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103d7a050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf8AiyAorblnoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11437a850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and the training accuracy\n",
    "plt.plot(loss)\n",
    "plt.title('training loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()    \n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.title('training accuracy')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
